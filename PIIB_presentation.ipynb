{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"A deep learning approach for epilepsy seizure identification using electroencephalogram signals\"\n",
        "author: \"Sergio Jácobo-Zavaleta\"\n",
        "date : \"17/07/2022\"\n",
        "margin : 0.05\n",
        "lang: es\n",
        "format: \n",
        "  revealjs:\n",
        "    incremental: true\n",
        "    theme : [default,Custom.scss]\n",
        "    logo: logo.png\n",
        "    footer: \"Programa de Investigación en Ingeniería Biomédica\"\n",
        "      \n",
        "---"
      ],
      "id": "c1d3b2ab"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "```{css, echo = FALSE}\n",
        ".red {\n",
        "  color: red;\n",
        "}\n",
        "```\n",
        "\n",
        "\n",
        "# .red{Introducción} {background-color=#ffff31}\n",
        "\n",
        "## Datos epidemiológicos de la Epilepsia\n",
        ":::: {.columns}\n",
        "\n",
        "::: {.column width=\"50%\"}\n",
        "- Cerca de 50 millones de todas las edades\n",
        "- Etiología múltiple\n",
        "  - Predisposición genética\n",
        "  - Meningitis/Encefalitis\n",
        "  - Trauma y tumores cerebrales\n",
        "  - Desórdenes degenerativos por la edad\n",
        ":::\n",
        "\n",
        "::: {.column width=\"50%\"}\n",
        "- 660 000 pacientes epilépticos\n",
        "- 15% reciben tratemiento\n",
        "- 30% con posibilidad de cirugía\n",
        "- Agravado por:\n",
        "  - Neurocisticercosis\n",
        "  - Paludismo (Enf. endémica)\n",
        ":::\n",
        "\n",
        "::::\n"
      ],
      "id": "6e25580c"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "### Planteamiento del Problema\n",
        ">> ¿Será posible mediante técnicas de machine learning implementar un modelo para identificación de pacientes epilépticos?\n",
        "\n",
        "### Hipótesis\n",
        ">> Mediante redes neuronales y técnicas de deep learning se podrá identificar convulsiones epilépticas utilizando señales de electroencafalograma.\n",
        "\n",
        "# Propuesta de solución {background-color=#76ff7a}\n",
        "## Data Selection\n",
        "- [TUH EEG Seizure Corpus (Última versión 1.5.4)](https://quarto.org/docs/presentations/revealjs/themes.html){preview-link=\"true\"}\n",
        "  - 675 personas, 1 643 sesiones, 1 475 horas (528        grab. contienen convulsiones)\n",
        "  - Data en European Data Format (EDF)\n",
        "  - Frecuencia de muestreo 250 Hz\n",
        "  - Sistema de electrodos 10/20, montaje bipolar          Temporal Central Parasagittal (TCP), 22 canales       EEG \n",
        "\n",
        "## Preparación de los datos\n",
        ":::: {.columns}\n",
        "\n",
        "::: {.column width=\"60%\"}\n",
        "#### Formulación de entrada\n",
        "![](Figuras/Figura1.svg){height=\"450\"}\n",
        ":::\n",
        "\n",
        "::: {.column width=\"40%\" .fragment}\n",
        "#### Datos E-V-E\n",
        "![](Figuras/Figura2.svg){height=\"460\"}\n",
        ":::\n",
        "\n",
        "::::\n",
        "\n",
        "\n",
        "\n",
        "## Preparación de los datos\n",
        "#### Formulación de la entrada\n",
        "\n",
        "![](Figuras/Figura3a.png){.absolute top=200 left=150 width=\"350\" height=\"300\"}\n",
        "![](Figuras/Figura3b.png){.absolute top=250 left=500 width=\"350\" height=\"300\"}\n",
        "\n",
        "\n",
        "\n",
        "## Arquitecturas de las redes\n",
        "![](Figuras/modelsArquitecture1.svg){.absolute top=100 left=0 height=\"500\"}\n",
        "![](Figuras/modelsArquitecture2.svg){.absolute top=200 left=530 height=\"300\"}\n",
        "\n",
        "# Resultados{background-color=#00ffff}\n",
        "## Métricas de rendimiento\n",
        "\n",
        ":::: {.columns}\n",
        "::: {.column width=\"50%\"}\n",
        "#### Para los datos de entrenamiento y validación\n",
        "![](Figuras/metricsTrainVal.svg){.absolute top=250 left=0 height=\"300\"}\n",
        ":::\n",
        "\n",
        "::: {.column width=\"50%\"}\n",
        "#### Para Evaluación\n",
        "- Evaluación simple\n",
        "![](Figuras/metricsEval1.svg){height=\"150\"}\n",
        "\n",
        "- Evaluación mixta\n",
        "![](Figuras/metricsEval2.svg){height=\"150\"}\n",
        ":::\n",
        "\n",
        "::::\n",
        "\n",
        "## Loss/Acc Entrenamiento + ROC + CM\n",
        "::: {.r-stack}\n",
        "![](Figuras/ConjuntoCurvas1.svg){.fragment .absolute top=75 left=10}\n",
        "\n",
        "![](Figuras/ConjuntoCurvas2.svg){.fragment .absolute top=75 left=10}\n",
        "\n",
        "![](Figuras/ConjuntoCurvas3.svg){.fragment .absolute top=75 left=10}\n",
        "\n",
        "![](Figuras/ConjuntoCurvas4.svg){.fragment .absolute top=75 left=10}\n",
        "\n",
        "![](Figuras/ConjuntoCurvas5.svg){.fragment .absolute top=75 left=10}\n",
        ":::\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Conclusiones{background-color=#ff1dce}\n",
        "\n",
        "\n",
        "<!-- \n",
        "\n",
        "![](https://raw.githubusercontent.com/quarto-dev/quarto-web/main/docs/get-started/hello/rstudio/lter_penguins.png){style=\"float:right;\" fig-alt=\"Illustration of three species of Palmer Archipelago penguins: Chinstrap, Gentoo, and Adelie. Artwork by @allison_horst.\" width=\"401\"}\n",
        "\n",
        "\n",
        "<https://quarto.org/docs/presentations/>. \n",
        "\n",
        "::: {.incremental}\n",
        "- Eat spaghetti\n",
        "- Drink wine\n",
        ":::\n",
        ".title{font-size:20px}\n",
        "\n",
        "## Slide Title {.smaller}\n",
        "## Slide Title {.scrollable}\n",
        "Or doing it globally:\n",
        "    smaller: true\n",
        "    scrollable: true\n",
        "\n",
        "::: {.notes}\n",
        "Speaker notes go here.\n",
        ":::\n",
        "\n",
        "::: aside\n",
        "Some additional commentary of more peripheral interest.\n",
        ":::\n",
        "\n",
        "- Green ^[A footnote]\n",
        "\n",
        "General option : reference-location: document\n",
        "\n",
        "A particular slide footer\n",
        "::: footer\n",
        "Custom footer text\n",
        ":::\n",
        "\n",
        "## Slide Title {background-video=\"video.mp4\" background-video-loop=\"true\" background-video-muted=\"true\"}\n",
        "\n",
        "## Slide Title {background-iframe=\"https://example.com\"}\n",
        "\n",
        "Genaral setting\n",
        "preview-links: auto\n",
        "\n",
        "[Preview](https://example.com){preview-link=\"true\"}\n",
        "\n",
        "[NoPreview](https://example.com){preview-link=\"false\"}\n",
        "\n",
        "::: {.r-stack}\n",
        "![](image1.png){.fragment width=\"450\" height=\"300\"}\n",
        "\n",
        "![](image2.png){.fragment width=\"300\" height=\"450\"}\n",
        "\n",
        "![](image3.png){.fragment width=\"400\" height=\"400\"}\n",
        ":::\n",
        "\n",
        "::: {.r-fit-text}\n",
        "Big Text\n",
        ":::\n",
        "\n",
        "![](image.png){.r-stretch}\n",
        "auto-stretch: false\n",
        "## Slide Title {.nostretch}\n",
        "\n",
        "## {auto-animate=true}\n",
        "\n",
        "Animation\n",
        "\n",
        "## {auto-animate=true}\n",
        "\n",
        "Implicit\n",
        "\n",
        "Animation\n",
        "\n",
        "-->"
      ],
      "id": "f65f26ec"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}